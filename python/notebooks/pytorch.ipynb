{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4504, 0.4566, 0.2301])\n",
      "tensor([0.])\n",
      "tensor([[-3.0273e+04,  3.0788e-41,  1.4256e-11],\n",
      "        [ 4.5755e-41,  1.4013e-45,  0.0000e+00],\n",
      "        [ 4.4842e-44,  0.0000e+00, -3.0388e+04]])\n",
      "tensor([[0.4464, 0.2369],\n",
      "        [0.4254, 0.8555]])\n",
      "tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "torch.int32\n",
      "tensor([3, 2, 4, 3])\n",
      "tensor([[0.0095],\n",
      "        [0.2251],\n",
      "        [0.7811],\n",
      "        [0.0972]])\n",
      "tensor([[3.0095, 2.0095, 4.0095, 3.0095],\n",
      "        [3.2251, 2.2251, 4.2251, 3.2251],\n",
      "        [3.7811, 2.7811, 4.7811, 3.7811],\n",
      "        [3.0972, 2.0972, 4.0972, 3.0972]])\n",
      "tensor([[3.0095, 2.0095, 4.0095, 3.0095],\n",
      "        [3.2251, 2.2251, 4.2251, 3.2251],\n",
      "        [3.7811, 2.7811, 4.7811, 3.7811],\n",
      "        [3.0972, 2.0972, 4.0972, 3.0972]])\n",
      "tensor([3.6934, 2.7673, 4.3220, 3.4786])\n",
      "tensor([-0.6934, -0.7673, -0.3220, -0.4786])\n",
      "tensor([11.0803,  5.5347, 17.2879, 10.4357])\n",
      "tensor([0.8123, 0.7227, 0.9255, 0.8624])\n",
      "tensor([[0.8843, 0.2418],\n",
      "        [0.5349, 0.6995],\n",
      "        [0.0281, 0.8223],\n",
      "        [0.2156, 0.5213],\n",
      "        [0.8244, 0.5502]])\n",
      "0.8843165636062622\n",
      "tensor([[0.8843, 0.2418, 0.6253, 0.5349, 0.6995],\n",
      "        [0.4523, 0.0281, 0.8223, 0.9179, 0.2156],\n",
      "        [0.5213, 0.8297, 0.8244, 0.5502, 0.1065]])\n",
      "tensor([0.8843, 0.2418, 0.6253, 0.5349, 0.6995, 0.4523, 0.0281, 0.8223, 0.9179,\n",
      "        0.2156, 0.5213, 0.8297, 0.8244, 0.5502, 0.1065])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = torch.rand(3)\n",
    "\n",
    "print(x)\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "x = torch.empty(1)\n",
    "print(x)\n",
    "x = torch.empty(3, 3)\n",
    "print(x)\n",
    "\n",
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "\n",
    "x = torch.ones(2, 2, dtype=torch.int)\n",
    "print(x)\n",
    "\n",
    "print(x.dtype)\n",
    "\n",
    "x = torch.tensor([3, 2, 4, 3])\n",
    "print(x)\n",
    "\n",
    "y = torch.rand(4, 1)\n",
    "\n",
    "z = x + y\n",
    "\n",
    "print(y)\n",
    "print(z)\n",
    "\n",
    "z = torch.add(x, y)\n",
    "print(z)\n",
    "\n",
    "y = torch.rand(x.shape)\n",
    "y.add_(x)\n",
    "print(y)\n",
    "\n",
    "z = torch.sub(x, y)\n",
    "print(z)\n",
    "\n",
    "z = torch.mul(x, y)\n",
    "print(z)\n",
    "\n",
    "z = torch.div(x, y)\n",
    "print(z)\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x[:, :2])\n",
    "\n",
    "print(x[0, 0].item())\n",
    "\n",
    "y = x.view(3, 5)\n",
    "print(y)\n",
    "z = x.view(15)\n",
    "print(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2.])\n",
      "[2. 2. 2. 2.]\n",
      "cpu\n",
      "tensor([2., 2., 2., 2.], dtype=torch.float64) tensor([1., 1., 1., 1.])\n",
      "True\n",
      "tensor([1., 1., 1., 1.], device='cuda:0')\n",
      "cuda:0\n",
      "tensor([2., 2., 2., 2.])\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.ones(4)\n",
    "\n",
    "b = a.numpy()\n",
    "\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "print(a.device)\n",
    "\n",
    "a = np.ones(4)\n",
    "b = torch.from_numpy(a)\n",
    "c = torch.Tensor(a)\n",
    "a += 1\n",
    "print(b, c)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(4, device = device)\n",
    "    print(x)\n",
    "    print(x.device)\n",
    "    y = torch.ones(4)\n",
    "    y = y.to(device)\n",
    "    z = x + y\n",
    "#     z.numpy() #error\n",
    "    z_cpu = z.to('cpu')\n",
    "    print(z_cpu)\n",
    "\n",
    "x = torch.ones(5, requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6080, -0.1171,  1.3756], requires_grad=True)\n",
      "tensor([2.6080, 1.8829, 3.3756], grad_fn=<AddBackward0>)\n",
      "tensor(14.4947, grad_fn=<MeanBackward0>)\n",
      "tensor([3.4774, 2.5105, 4.5008])\n",
      "tensor([ 4.5206, 10.0421,  4.5144])\n",
      "tensor([2.6080, 1.8829, 3.3756])\n",
      "tensor([2.6080, 1.8829, 3.3756])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "\n",
    "z = y * y * 2\n",
    "z = z.mean()\n",
    "print(z)\n",
    "\n",
    "z.backward() # dz/dx\n",
    "print(x.grad)\n",
    "\n",
    "z = y * y * 2\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v)\n",
    "print(x.grad)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x + 2\n",
    "    print(y)\n",
    "\n",
    "x.requires_grad_(False)\n",
    "y = x + 2\n",
    "print(y)\n",
    "# x.detach()\n",
    "\n",
    "\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    \n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "    \n",
    "    weights.grad.zero_()\n",
    "\n",
    "# optimizer = torch.optim.SGD(weights, lr=0.01)\n",
    "# optimizer.step()\n",
    "# optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "## Backpropagation\n",
    "\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "y_hat = w * x\n",
    "\n",
    "loss = (y_hat - y)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 1.200000, loss = 30.00000000\n",
      "epoch 3: w = 1.872000, loss = 0.76800019\n",
      "epoch 5: w = 1.979520, loss = 0.01966083\n",
      "epoch 7: w = 1.996723, loss = 0.00050331\n",
      "epoch 9: w = 1.999476, loss = 0.00001288\n",
      "epoch 11: w = 1.999916, loss = 0.00000033\n",
      "epoch 13: w = 1.999987, loss = 0.00000001\n",
      "epoch 15: w = 1.999998, loss = 0.00000000\n",
      "epoch 17: w = 2.000000, loss = 0.00000000\n",
      "epoch 19: w = 2.000000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# gradients using numpy\n",
    "\n",
    "# f = w * x = 2 * x\n",
    "X = np.array([1, 2, 3, 4]).astype(np.float32)\n",
    "\n",
    "Y = np.array([2, 4, 6, 8]).astype(np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x - y)**2\n",
    "#d3/dw = 1/N 2x(w*x - y)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2*x, y_predicted - y).mean()\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    #loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    dw = gradient(X,Y,y_pred)\n",
    "    \n",
    "    #update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'learning_rcte' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-28677c8f0b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rcte\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# zero gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learning_rcte' is not defined"
     ]
    }
   ],
   "source": [
    "# gradients using torch\n",
    "\n",
    "# f = w * x = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted - y)**2).mean()\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    #loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    \n",
    "    #update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rcte * w.grad\n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before training: f(5) = -2.710\n",
      "epoch 1: w = -0.004448, loss = 52.22869873\n",
      "epoch 11: w = 1.651543, loss = 1.35265708\n",
      "epoch 21: w = 1.918677, loss = 0.03629294\n",
      "epoch 31: w = 1.962391, loss = 0.00215996\n",
      "epoch 41: w = 1.970147, loss = 0.00120578\n",
      "epoch 51: w = 1.972098, loss = 0.00111416\n",
      "epoch 61: w = 1.973094, loss = 0.00104876\n",
      "epoch 71: w = 1.973917, loss = 0.00098770\n",
      "epoch 81: w = 1.974692, loss = 0.00093021\n",
      "epoch 91: w = 1.975440, loss = 0.00087607\n",
      "Prediction after training: f(5) = 9.951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) design model (input, output size, forward pass)\n",
    "# 2) construct loss and optimizer\n",
    "# 3) Training loops\n",
    "#   - forward pass: compute prediction\n",
    "#   - backward pass: gradients\n",
    "#   - update weights\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# # model prediction\n",
    "# def forward(x):\n",
    "#     return w * x\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "# # loss = MSE\n",
    "# def loss(y, y_predicted):\n",
    "#     return ((y_predicted - y)**2).mean()\n",
    "loss = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward\n",
    "#     y_pred = forward(X)\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    #loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    #gradients\n",
    "    l.backward() # dl/dw\n",
    "    \n",
    "    \n",
    "#     #update weights\n",
    "#     with torch.no_grad():\n",
    "#         w -= learning_rcte * w.grad\n",
    "    \n",
    "#     # zero gradients\n",
    "#     w.grad.zero_()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch {epoch+1}: w = {w[0][0].item():3f}, loss = {l:.8f}')\n",
    "#         print(f'epoch {epoch+1}: w = {w:3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, loss = 561.0742\n",
      "epoch 200, loss = 342.4601\n",
      "epoch 300, loss = 333.0042\n",
      "epoch 400, loss = 332.5870\n",
      "epoch 500, loss = 332.5684\n",
      "epoch 600, loss = 332.5676\n",
      "epoch 700, loss = 332.5675\n",
      "epoch 800, loss = 332.5676\n",
      "epoch 900, loss = 332.5676\n",
      "epoch 1000, loss = 332.5676\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'epoch {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# plot\n",
    "predicted = model(X).detach()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, loss = 0.2488\n",
      "epoch 200, loss = 0.1771\n",
      "epoch 300, loss = 0.1456\n",
      "epoch 400, loss = 0.1274\n",
      "epoch 500, loss = 0.1154\n",
      "epoch 600, loss = 0.1067\n",
      "epoch 700, loss = 0.1001\n",
      "epoch 800, loss = 0.0949\n",
      "epoch 900, loss = 0.0906\n",
      "epoch 1000, loss = 0.0870\n",
      "accuracy = 0.9561\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "# 1) model\n",
    "\n",
    "# f = wx + b, sigmoid at the end\n",
    "\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "\n",
    "model = LogisticRegression(input_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'epoch {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# eval\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')\n",
    "    \n",
    "# plot\n",
    "# predicted = model(X_test).detach()\n",
    "# plt.plot(X_test, y, 'ro')\n",
    "# plt.plot(X_numpy, predicted, 'b')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('./data/ignore/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1 shape\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, target\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "\n",
    "\n",
    "# dataset = WineDataset(transform=ToTensor())\n",
    "# dataset = WineDataset(transform=composed)\n",
    "dataset = WineDataset(transform=None)\n",
    "# first_data = dataset[0]\n",
    "# features, labels = first_data\n",
    "# print(features, labels)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "\n",
    "# data = dataiter.next()\n",
    "# features, labels = data\n",
    "# print(features, labels)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "# print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward, backward, update\n",
    "        if (i+1)%5 == 0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step{i+1}/{n_iterations}, inputs {inputs.shape}')\n",
    "\n",
    "# torchvision.datasets.MNIST()\n",
    "# fashion-mnist, cifar, coco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c7a5a7c0579b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m dataset = torchvision.datasets.MNIST(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[1;32m     74\u001b[0m                                ' You can use download=True to download it')\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/ignore/', transform=torchvision.transforms.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65900114 0.24243297 0.09856589]\n",
      "tensor([0.6590, 0.2424, 0.0986])\n",
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n",
      "0.45854488015174866\n",
      "1.8897881507873535\n",
      "tensor([2, 0, 1])\n",
      "tensor([1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1, 0.1])\n",
    "\n",
    "outputs = softmax(x)\n",
    "print(outputs)\n",
    "\n",
    "x = torch.tensor([2, 1, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(outputs)\n",
    "\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # /  float(predicted.shape[0])\n",
    "\n",
    "# y must be one hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "Y = np.array([1, 0, 0])\n",
    "\n",
    "# y_pred has probabilites\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')\n",
    "\n",
    "\n",
    "# torch\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "# nsamples x nclasses = 1x3\n",
    "Y_pred_good = torch.tensor([[.1, 1.0, 2.1], [2.1, 1.0, 2.], [.1, 3.0, 1.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3], [0.5, 2.0, 0.3], [2.5, 1.0, 0.3]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item())\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1)\n",
    "print(predictions2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNet2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Binary classification\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # signmoid at the end\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
    "criterion = nn.BCELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activation functions\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# option1 (create nn modules)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "#         nn.Sigmoid\n",
    "#         nn.Softmax\n",
    "#         nn.TanH\n",
    "#         nn.LeakyReLU\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "# option1 (use activation functions directly in forward pass)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "epoch 1 / 2, step 100/600, loss = 0.4406\n",
      "epoch 1 / 2, step 200/600, loss = 0.2648\n",
      "epoch 1 / 2, step 300/600, loss = 0.3180\n",
      "epoch 1 / 2, step 400/600, loss = 0.3850\n",
      "epoch 1 / 2, step 500/600, loss = 0.2314\n",
      "epoch 1 / 2, step 600/600, loss = 0.2968\n",
      "epoch 2 / 2, step 100/600, loss = 0.3493\n",
      "epoch 2 / 2, step 200/600, loss = 0.2228\n",
      "epoch 2 / 2, step 300/600, loss = 0.1951\n",
      "epoch 2 / 2, step 400/600, loss = 0.1592\n",
      "epoch 2 / 2, step 500/600, loss = 0.1521\n",
      "epoch 2 / 2, step 600/600, loss = 0.0749\n",
      "accuracy = 95.29\n"
     ]
    }
   ],
   "source": [
    "# feedforward.py\n",
    "# MNIST\n",
    "# DataLoader, Transformation\n",
    "# Multilayer Neural Net, activation fucntion\n",
    "# Loss and Optimizer\n",
    "# Training Loop (batch training)\n",
    "# Model evaluation\n",
    "# GPU support\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/ignore/', train=True,\n",
    "                                          transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/ignore/', train=False,\n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2, 3, i+1)\n",
    "#     plt.imshow(samples[i][0], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # 100 x 784\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "        \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch 1 / 4, step 2000/12500, loss = 2.2815\n",
      "epoch 1 / 4, step 4000/12500, loss = 2.2737\n",
      "epoch 1 / 4, step 6000/12500, loss = 2.2999\n",
      "epoch 1 / 4, step 8000/12500, loss = 2.2941\n",
      "epoch 1 / 4, step 10000/12500, loss = 2.2146\n",
      "epoch 1 / 4, step 12000/12500, loss = 1.9389\n",
      "epoch 2 / 4, step 2000/12500, loss = 2.2308\n",
      "epoch 2 / 4, step 4000/12500, loss = 1.6168\n",
      "epoch 2 / 4, step 6000/12500, loss = 1.4803\n",
      "epoch 2 / 4, step 8000/12500, loss = 1.5485\n",
      "epoch 2 / 4, step 10000/12500, loss = 2.2059\n",
      "epoch 2 / 4, step 12000/12500, loss = 1.7959\n",
      "epoch 3 / 4, step 2000/12500, loss = 1.2699\n",
      "epoch 3 / 4, step 4000/12500, loss = 1.3085\n",
      "epoch 3 / 4, step 6000/12500, loss = 1.9914\n",
      "epoch 3 / 4, step 8000/12500, loss = 1.3287\n",
      "epoch 3 / 4, step 10000/12500, loss = 1.5374\n",
      "epoch 3 / 4, step 12000/12500, loss = 2.6831\n",
      "epoch 4 / 4, step 2000/12500, loss = 1.5150\n",
      "epoch 4 / 4, step 4000/12500, loss = 1.7602\n",
      "epoch 4 / 4, step 6000/12500, loss = 1.4767\n",
      "epoch 4 / 4, step 8000/12500, loss = 1.5640\n",
      "epoch 4 / 4, step 10000/12500, loss = 0.6324\n",
      "epoch 4 / 4, step 12000/12500, loss = 1.0657\n",
      "Finished Training\n",
      "accuracy of network = 9.94 %\n",
      "Accuracy of plane: 51.9 %\n",
      "Accuracy of car: 58.7 %\n",
      "Accuracy of bird: 24.7 %\n",
      "Accuracy of cat: 27.5 %\n",
      "Accuracy of deer: 42.3 %\n",
      "Accuracy of dog: 48.5 %\n",
      "Accuracy of frog: 61.1 %\n",
      "Accuracy of horse: 56.2 %\n",
      "Accuracy of ship: 57.5 %\n",
      "Accuracy of truck: 45.0 %\n"
     ]
    }
   ],
   "source": [
    "# Convolutional neural networks using pytorch\n",
    "# cnn.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImage images of range [0, 1]\n",
    "# we transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# CIFAR10\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/ignore/', train=True,\n",
    "                                          transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/ignore/', train=False,\n",
    "                                          transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# implement conv net\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape = [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer = 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backwards and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "    \n",
    "print('Finished Training')\n",
    "\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy of network = {acc} %')\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
